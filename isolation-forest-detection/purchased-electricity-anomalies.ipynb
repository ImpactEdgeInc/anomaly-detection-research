{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f31bf54-1dd7-459a-83a2-d95c13ff4602",
   "metadata": {},
   "source": [
    "# Detecting Anomalies In Purchased Electricity (Scope 2) Data Through Isolated Forests\n",
    "\n",
    "## Package Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eca41835-59ac-4ddb-b221-eb27638ac77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925b0af6-4df6-4bcb-be83-2f56d7cf9fa4",
   "metadata": {},
   "source": [
    "## Database Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dad8a5b-f90b-4673-8491-94a56892cb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 facilityId         co2e  \\\n",
      "0      68f4851d-4959-49b6-96a1-63d80c816ed3     0.023896   \n",
      "1      bf2278d8-0d33-4e28-a55e-ad3c1537af7e     0.002868   \n",
      "2      bf2278d8-0d33-4e28-a55e-ad3c1537af7e     0.000810   \n",
      "3      2af3b5a4-c50c-4e19-bf57-966f7d5eb4d0     0.657275   \n",
      "4      2af3b5a4-c50c-4e19-bf57-966f7d5eb4d0     0.646236   \n",
      "...                                     ...          ...   \n",
      "29800  829c1cb0-918f-4a92-bdf0-9072faf8cf5f     1.309540   \n",
      "29801  b4a32a71-f70c-4655-bb4f-94c2c96c27b5     0.177120   \n",
      "29802  5b779dd3-79ad-4ffe-b961-69a20328d4a2     1.018440   \n",
      "29803  a527d218-da19-45ea-9e0e-8f191d2ffc8a     0.503480   \n",
      "29804  c062e8df-c057-43b7-8b2a-6beed46cf636  4275.815688   \n",
      "\n",
      "                    fuelType                         createdAt       ch4  \\\n",
      "0                       AKMS  2025-01-05 22:00:45.524000-08:00  0.000001   \n",
      "1                       AKMS  2025-01-19 09:40:06.100000-08:00  0.000000   \n",
      "2                 QUEENSLAND  2025-01-19 18:43:21.692000-08:00  0.000000   \n",
      "3                       FRCC  2025-01-19 22:13:51.441000-08:00  0.000046   \n",
      "4                       FRCC  2025-01-19 22:13:52.144000-08:00  0.000046   \n",
      "...                      ...                               ...       ...   \n",
      "29800  ELECTRICITY_FROM_GRID  2025-04-24 09:20:35.455000-07:00  0.000016   \n",
      "29801  ELECTRICITY_FROM_GRID  2025-04-24 09:20:47.632000-07:00  0.000002   \n",
      "29802  ELECTRICITY_FROM_GRID  2025-04-24 09:20:59.471000-07:00  0.000012   \n",
      "29803  ELECTRICITY_FROM_GRID  2025-04-24 09:21:11.470000-07:00  0.000006   \n",
      "29804                   NYLI  2025-05-20 10:24:00.407000-07:00  0.000000   \n",
      "\n",
      "            n2o        ef          co2  \n",
      "0      0.000000  0.238959     0.023817  \n",
      "1      0.000000  0.238959     0.002858  \n",
      "2      0.000000  0.810000     0.000810  \n",
      "3      0.000006  0.424596     0.654303  \n",
      "4      0.000006  0.424596     0.643314  \n",
      "...         ...       ...          ...  \n",
      "29800  0.000012  0.820000     1.261630  \n",
      "29801  0.000002  0.820000     0.170640  \n",
      "29802  0.000010  0.820000     0.981180  \n",
      "29803  0.000005  0.820000     0.485060  \n",
      "29804  0.000000  0.534477  4275.815688  \n",
      "\n",
      "[29805 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "import psycopg2\n",
    "\n",
    "dotenv.load_dotenv(dotenv_path='database.env')\n",
    "\n",
    "# --- Configuration ---\n",
    "DB_NAME = os.environ['DB_NAME']\n",
    "DB_USER = os.environ['DB_USER']\n",
    "DB_PASS = os.environ['DB_PASS']\n",
    "HOST = os.environ['HOST']\n",
    "PORT = os.environ['PORT']\n",
    "\n",
    "# 2. Database Connection and Setup\n",
    "conn = psycopg2.connect(\n",
    "    dbname=DB_NAME, user=DB_USER, password=DB_PASS, host=HOST, port=PORT\n",
    ")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('SELECT \"facilityId\",\"co2e\",\"fuelType\",\"createdAt\",\"ch4\",\"n2o\",\"ef\",\"co2\" FROM purchased_electricity_activity')\n",
    "\n",
    "df = pd.DataFrame(cur.fetchall(), columns = [\"facilityId\",\"co2e\",\"fuelType\",\"createdAt\",\"ch4\",\"n2o\",\"ef\",\"co2\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5497ecb-fccf-4317-8912-c2eeb194246c",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "We will first create hour, day of week, and month-based variables to account for factors like seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc22c7b-e4fb-42ce-80bd-b6a0faf9f23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'createdAt' to datetime objects\n",
    "df['createdAt'] = pd.to_datetime(df['createdAt'], utc=True)\n",
    "\n",
    "# --- 2. Feature Engineering ---\n",
    "\n",
    "# Extract time-based features\n",
    "df['hour'] = df['createdAt'].dt.hour\n",
    "df['day_of_week'] = df['createdAt'].dt.dayofweek # Monday=0, Sunday=6\n",
    "df['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "df['month'] = df['createdAt'].dt.month\n",
    "\n",
    "# For cyclical seasonality, convert month to sine and cosine features\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month']/12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month']/12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fd7e6e-7294-49ee-821c-35abdf090a65",
   "metadata": {},
   "source": [
    "This section of code factors in a manual \"event log\" that can account for changes in production, such as a facility being inactive during a certain period of time, or producing higher rates of a product during a certain busy time, and factoring that into the emission readings accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5a120ce-afea-4b09-8150-29d4f9d875d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied production boost to 102 records.\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Event Log Integration and Feature Creation ---\n",
    "\n",
    "# 1. Simulate the Event Log (This is where the user/system input goes)\n",
    "# Example: Facility X increases production by 50% from June 1st to July 31st\n",
    "event_log = pd.read_csv(\"sample_event_log.csv\")\n",
    "\n",
    "# 2. Initialize the new feature to the baseline (1.0, meaning no change)\n",
    "df['production_boost_factor'] = 1.0\n",
    "\n",
    "# 3. Apply the boost factor for records that fall within event periods\n",
    "for _, event in event_log.iterrows():\n",
    "    # Check if a record is from the facility AND within the event's date range\n",
    "    mask = (df['facilityId'] == event['facilityId']) & \\\n",
    "           (df['createdAt'] >= event['event_start']) & \\\n",
    "           (df['createdAt'] <= event['event_end'])\n",
    "    \n",
    "    # Apply the magnitude to the new feature column\n",
    "    df.loc[mask, 'production_boost_factor'] = event['magnitude']\n",
    "\n",
    "print(f\"Applied production boost to {df[df['production_boost_factor'] > 1.0].shape[0]} records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b3c631-0f97-457f-ae72-6e3f7859dba1",
   "metadata": {},
   "source": [
    "We keep the necessary features in our data and prepare the data for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8323a83-cb22-457b-8490-9f4c4bd97d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features to be used in the model\n",
    "NUMERICAL_FEATURES = ['co2e', 'ch4', 'n2o', 'ef', 'co2', 'month_sin', 'month_cos', 'production_boost_factor']\n",
    "TIME_FEATURES = ['hour', 'day_of_week', 'is_weekend']\n",
    "CATEGORICAL_FEATURES = ['facilityId', 'fuelType']\n",
    "\n",
    "FEATURES = NUMERICAL_FEATURES + TIME_FEATURES + CATEGORICAL_FEATURES\n",
    "X = df[FEATURES]\n",
    "\n",
    "# --- 3. Preprocessing Pipeline ---\n",
    "\n",
    "# Create transformers for different feature types\n",
    "numerical_transformer = StandardScaler() # Scaling is crucial for Isolation Forest\n",
    "\n",
    "# One-Hot Encoding for categorical features\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, NUMERICAL_FEATURES + TIME_FEATURES),\n",
    "        ('cat', categorical_transformer, CATEGORICAL_FEATURES)\n",
    "    ],\n",
    "    remainder='drop' # Drop other columns not specified\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb8dfeb-3ceb-4994-b9ad-7f3efa0eeab6",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "This section is where we define and create our model. We train it to prioritize recent data (such as in the last six months) and fit our data to the model. `X_recent` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f385b058-24fe-450c-bff6-a4505d6503e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Isolation Forest model...\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# The Isolation Forest model is typically trained on all data since we don't have labeled anomalies.\n",
    "# 'contamination' is the expected proportion of anomalies in the dataset (e.g., 1%).\n",
    "# Setting a reasonable contamination value helps the model set its internal threshold.\n",
    "\n",
    "# Define the model within a pipeline for clean preprocessing and fitting\n",
    "anomaly_detector = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', IsolationForest(\n",
    "        n_estimators=100,\n",
    "        contamination=0.01, # Set based on domain knowledge (e.g., 1% of data is anomalous)\n",
    "        random_state=42,\n",
    "        n_jobs=-1 # Use all available cores\n",
    "    ))\n",
    "])\n",
    "\n",
    "# --- 5. Training and Prediction ---\n",
    "\n",
    "print(\"Training Isolation Forest model...\")\n",
    "\n",
    "# Assuming 'df' is your historical data and you want to use the last 6 months\n",
    "six_months_ago = pd.to_datetime('today', utc=True) - pd.DateOffset(months=6)\n",
    "\n",
    "# Filter the data for the rolling window\n",
    "recent_data = df[df['createdAt'] >= six_months_ago]\n",
    "X_recent = recent_data[FEATURES]\n",
    "\n",
    "anomaly_detector.fit(X)\n",
    "\n",
    "# Get the anomaly scores (lower score means more anomalous)\n",
    "# Note: Isolation Forest outputs a score where higher is 'normal'.\n",
    "# We often use .decision_function() for the raw score.\n",
    "df['anomaly_score'] = anomaly_detector.decision_function(X)\n",
    "\n",
    "# Predict the anomaly classification (-1 for anomaly, 1 for normal)\n",
    "df['anomaly_label'] = anomaly_detector.predict(X)\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb249bdf-ef3d-4fea-9006-9be4a6fa93e0",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5a02f0e-5149-47ad-9dc1-15de09f5f26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results Summary ---\n",
      "Total Anomalies Detected (-1): 294\n",
      "Total Normal Observations (1): 29511\n",
      "\n",
      "Top 5 Most Anomalous Records:\n",
      "                             createdAt               fuelType         co2e  \\\n",
      "19832 2025-04-24 15:16:22.060000+00:00  ELECTRICITY_FROM_GRID  2094.721778   \n",
      "19852 2025-04-24 16:12:35.313000+00:00  ELECTRICITY_FROM_GRID  2774.705488   \n",
      "9917  2025-04-24 16:12:35.313000+00:00  ELECTRICITY_FROM_GRID  2774.705488   \n",
      "9897  2025-04-24 15:16:22.060000+00:00  ELECTRICITY_FROM_GRID  2094.721778   \n",
      "29767 2025-04-24 15:16:22.060000+00:00  ELECTRICITY_FROM_GRID  2094.721778   \n",
      "...                                ...                    ...          ...   \n",
      "9869  2025-04-24 13:35:22.956000+00:00  ELECTRICITY_FROM_GRID   206.498960   \n",
      "19804 2025-04-24 13:35:22.956000+00:00  ELECTRICITY_FROM_GRID   206.498960   \n",
      "9850  2025-04-24 12:44:53.009000+00:00  ELECTRICITY_FROM_GRID   200.084100   \n",
      "19785 2025-04-24 12:44:53.009000+00:00  ELECTRICITY_FROM_GRID   200.084100   \n",
      "29720 2025-04-24 12:44:53.009000+00:00  ELECTRICITY_FROM_GRID   200.084100   \n",
      "\n",
      "       anomaly_score  \n",
      "19832      -0.021447  \n",
      "19852      -0.021447  \n",
      "9917       -0.021447  \n",
      "9897       -0.021447  \n",
      "29767      -0.021447  \n",
      "...              ...  \n",
      "9869       -0.000237  \n",
      "19804      -0.000237  \n",
      "9850       -0.000237  \n",
      "19785      -0.000237  \n",
      "29720      -0.000237  \n",
      "\n",
      "[294 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Results Summary ---\")\n",
    "print(f\"Total Anomalies Detected (-1): {df['anomaly_label'].value_counts().get(-1, 0)}\")\n",
    "print(f\"Total Normal Observations (1): {df['anomaly_label'].value_counts().get(1, 0)}\")\n",
    "\n",
    "# --- 6. Inspection of Anomalies ---\n",
    "\n",
    "anomalies = df[df['anomaly_label'] == -1].sort_values(by='anomaly_score')\n",
    "\n",
    "# Show the top 5 most anomalous observations (lowest scores)\n",
    "print(\"\\nTop 5 Most Anomalous Records:\")\n",
    "print(anomalies[['createdAt','fuelType', 'co2e', 'anomaly_score']])\n",
    "\n",
    "# Example of how to filter based on a score threshold if you prefer a continuous approach\n",
    "# score_threshold = df['anomaly_score'].quantile(0.01) # Set threshold at the 1st percentile\n",
    "# high_risk = df[df['anomaly_score'] < score_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "451a5a7b-3a9c-405b-8aa6-10dedec7df98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ELECTRICITY_FROM_GRID' 'HIOA' 'ERCT' 'NYLI']\n",
      "facilityId                 141\n",
      "co2e                       141\n",
      "fuelType                   141\n",
      "createdAt                  141\n",
      "ch4                        141\n",
      "n2o                        141\n",
      "ef                         141\n",
      "co2                        141\n",
      "hour                       141\n",
      "day_of_week                141\n",
      "is_weekend                 141\n",
      "month                      141\n",
      "month_sin                  141\n",
      "month_cos                  141\n",
      "production_boost_factor    141\n",
      "anomaly_score              141\n",
      "anomaly_label              141\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(anomalies['fuelType'].unique())\n",
    "\n",
    "print(anomalies[anomalies['fuelType'] == \"ELECTRICITY_FROM_GRID\"].count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
